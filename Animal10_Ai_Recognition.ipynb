{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnmenibXLwIT"
      },
      "outputs": [],
      "source": [
        "# Animal Image Classifier (Animals-10)\n",
        "\n",
        "This project trains a **ResNet50** deep learning model on the [Animals-10 dataset](https://www.kaggle.com/datasets/alessiocorrado99/animals10) to classify photos of 10 different animals:\n",
        "Dog, Cat, Elephant, Cow, Horse, Sheep, Chicken, Spider, Squirrel, Butterfly.\n",
        "\n",
        "The notebook uses **PyTorch** for training and **Gradio** for an interactive web demo.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# GPU check\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "qAjg2QmKL7OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Kaggle and download the dataset (if not already done)\n",
        "!mkdir -p ~/.kaggle\n",
        "from google.colab import files\n",
        "files.upload()  # upload your kaggle.json manually\n",
        "\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d alessiocorrado99/animals10\n",
        "!unzip -q animals10.zip -d animals_dataset\n"
      ],
      "metadata": {
        "id": "RabNlhN_L-1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd animals_dataset/raw-img\n",
        "\n",
        "mv cane dog\n",
        "mv cavallo horse\n",
        "mv elefante elephant\n",
        "mv farfalla butterfly\n",
        "mv gallina chicken\n",
        "mv gatto cat\n",
        "mv mucca cow\n",
        "mv pecora sheep\n",
        "mv ragno spider\n",
        "mv scoiattolo squirrel\n",
        "\n",
        "cd /content\n"
      ],
      "metadata": {
        "id": "MYKqIltAL_Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = datasets.ImageFolder(\"animals_dataset/raw-img\", transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_data, batch_size=32, num_workers=2)\n",
        "\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(f\"Training samples: {len(train_data)} | Testing samples: {len(test_data)}\")\n"
      ],
      "metadata": {
        "id": "rlOSgYO5MBOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained ResNet50\n",
        "model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "# Adjust the final fully connected layer for 10 classes\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "print(\"Model ready for training\")\n"
      ],
      "metadata": {
        "id": "BsFs3ITYMC1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "train_losses, train_accuracies = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Zsoq5NB8MGc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_acc = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "E69CFmg2MH7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"animal_classifier.pth\")\n",
        "print(\"Model saved as animal_classifier.pth\")\n"
      ],
      "metadata": {
        "id": "l75-70qVMJZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def classify_image(img):\n",
        "    model.eval()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    x = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(x)\n",
        "        probs = F.softmax(outputs, dim=1)[0]\n",
        "    return {dataset.classes[i]: float(probs[i]) for i in range(len(probs))}\n",
        "\n",
        "gr.Interface(\n",
        "    fn=classify_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Label(num_top_classes=3),\n",
        "    title=\"üêæ Animal Classifier\",\n",
        "    description=\"Upload a photo of an animal (dog, cat, elephant, etc.) to see what the model predicts!\"\n",
        ").launch(share=True)\n"
      ],
      "metadata": {
        "id": "z4oq25BCMLYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}